{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3769c1-f61d-4e12-9efb-a216d86eda56",
   "metadata": {},
   "source": [
    "# Day 54 – Naive Bayes Classifier\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, I explore the **Naive Bayes Classifier**, a family of probabilistic algorithms based on Bayes’ Theorem with the assumption of feature independence. **Naive Bayes Classifier** is a powerful and efficient supervised learning algorithm based on **Bayes' Theorem**. Its simplicity and speed make it a popular choice for many tasks, especially in text classification and spam filtering.\n",
    "\n",
    "I begin with the theory behind conditional probability, Bayes’ Theorem, and how Naive Bayes works, followed by its real-world applications. Then I implement and compare the three main types of Naive Bayes classifiers:  \n",
    "- **GaussianNB** (for continuous features)  \n",
    "- **MultinomialNB** (for count-based features)  \n",
    "- **BernoulliNB** (for binary features)  \n",
    "\n",
    "Each classifier is tested under different preprocessing approaches — without scaling, with StandardScaler, and with Normalizer — to observe how scaling impacts their performance.  \n",
    "\n",
    "By the end of this notebook, it becomes clear which Naive Bayes variants are sensitive to scaling, why MultinomialNB fails with StandardScaler, and how each algorithm behaves under different scenarios, giving practical insights into choosing the right variant for a dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dccc4ae-ecd1-4b6f-91c6-d0b009b29de9",
   "metadata": {},
   "source": [
    "\n",
    "## 1. The Foundation: Conditional Probability and Bayes' Theorem\n",
    "\n",
    "To understand Naive Bayes, we must first grasp two core concepts from probability.\n",
    "\n",
    "### Conditional Probability\n",
    "\n",
    "Conditional Probability is the likelihood of an event occurring, given that another event has already happened. We write it as $P(A|B)$, which means \"the probability of event A given event B.\"\n",
    "\n",
    "* **Example**: The probability of a student getting a high score on a test ($A$) given that they studied for many hours ($B$).\n",
    "\n",
    "Mathematically:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A ∩ B)}{P(B)}$$\n",
    "\n",
    "\n",
    "- \\( P(A|B) \\) = Probability of A given B  \n",
    "- \\( P(A ∩ B) \\) = Probability that both A and B occur  \n",
    "- \\( P(B) \\) = Probability of B  \n",
    "\n",
    "Example: Suppose 30% of people like coffee, and among coffee lovers, 60% also like tea.  \n",
    "- Here, \\( P(Tea|Coffee) = 0.6 \\).\n",
    "\n",
    "### Bayes' Theorem\n",
    "\n",
    "Bayes’ Theorem provides a way to **update probabilities** when new evidence (data) is observed. It is a way to calculate conditional probability by using other known probabilities. It's the mathematical formula that allows us to update our beliefs about an event based on new evidence.\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A) \\times P(A)}{P(B)}$$\n",
    "\n",
    "* $P(A|B)$: The **posterior probability** (what we want to find). The probability of event A happening given event B has occurred.\n",
    "* $P(B|A)$: The **likelihood**. The probability of event B happening given event A is true.\n",
    "* $P(A)$: The **prior probability**. The initial probability of event A happening.\n",
    "* $P(B)$: The **evidence**. The probability of event B happening.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The Naive Bayes Algorithm\n",
    "\n",
    "The Naive Bayes algorithm applies Bayes' Theorem to a classification problem. It uses a \"naive\" assumption to simplify the complex calculations of conditional probability.\n",
    "\n",
    "### The \"Naive\" Assumption\n",
    "The algorithm assumes that all features in a dataset are **independent** of each other. In other words, it assumes that the value of one feature (e.g., a person's age) does not influence the value of another feature (e.g., their salary). While this assumption is rarely true in the real world, it greatly simplifies the model and makes it incredibly fast and efficient.\n",
    "\n",
    "**Why \"Naive\"?**  \n",
    "- It assumes that **all features are independent given the class**.  \n",
    "- In real life, this is rarely true, but the algorithm still works surprisingly well.\n",
    "\n",
    "### How it works\n",
    "The algorithm calculates the probability of each class for a given set of features and then assigns the class with the highest probability to the new data point.\n",
    "\n",
    "* For example, in a spam filter, Naive Bayes calculates:\n",
    "    * The probability that an email is spam, given its words.\n",
    "    * The probability that an email is not spam, given its words.\n",
    "* It then classifies the email as spam or not spam based on which of these two probabilities is higher.\n",
    "\n",
    "### Steps in Naive Bayes classification:**\n",
    "1. Calculate prior probability for each class.  \n",
    "2. Calculate conditional probability for each feature given the class.  \n",
    "3. Apply Bayes’ theorem to compute posterior probability for each class.  \n",
    "4. Choose the class with the highest posterior probability.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Real-Time Example of Naive Bayes\n",
    "\n",
    "**Spam Email Detection:**\n",
    "- Features: words present in an email.  \n",
    "- Classes: *Spam* or *Not Spam*.  \n",
    "- The algorithm calculates probabilities like:  \n",
    "  - \\( P(Spam|Word = \"Free\") \\)  \n",
    "  - \\( P(NotSpam|Word = \"Free\") \\)  \n",
    "- If the probability of Spam is higher, the email is classified as Spam.  \n",
    "\n",
    "Naive Bayes is widely used in:\n",
    "- Text classification (spam filtering, sentiment analysis, document categorization)  \n",
    "- Medical diagnosis  \n",
    "- Real-time predictions where speed is crucial  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Types of Naive Bayes\n",
    "\n",
    "There are **three main variants** of Naive Bayes, chosen based on the type of data:\n",
    "\n",
    "1. **Gaussian Naive Bayes**  \n",
    "   - Assumes features are continuous and follow a **normal (Gaussian) distribution**.  \n",
    "   - Common for numeric features like age, salary, measurements.\n",
    "\n",
    "2. **Multinomial Naive Bayes**  \n",
    "   - Used for **discrete counts** (e.g., word counts in text classification).  \n",
    "   - Feature values must be non-negative integers.  \n",
    "   - Very popular in NLP applications.\n",
    "\n",
    "3. **Bernoulli Naive Bayes**  \n",
    "   - Features are assumed to be **binary** (0 or 1).  \n",
    "   - Example: presence or absence of a word in text.  \n",
    "   - Suitable when features are indicators rather than counts.\n",
    "\n",
    "The choice of Naive Bayes classifier depends on the nature of your data's features.\n",
    "\n",
    "\n",
    "| Classifier | Data Type | Key Characteristic | Common Use Case |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Gaussian Naive Bayes** | Continuous | Assumes features follow a **Gaussian (Normal) distribution**. | Continuous numerical data, like age, height, or salary. |\n",
    "| **Multinomial Naive Bayes** | Discrete | Used for **count-based data**. | Text classification, where features are word counts or frequencies. |\n",
    "| **Bernoulli Naive Bayes** | Binary | Used for **binary features**. | Document classification, where a feature indicates whether a word is present (1) or not (0). |\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Advantages and Limitations\n",
    "\n",
    "**Advantages:**\n",
    "- Simple, fast, and efficient for large datasets.\n",
    "- Works well with text classification problems (spam, sentiment).\n",
    "- Requires less training data compared to many other algorithms.\n",
    "\n",
    "**Limitations:**\n",
    "- Strong independence assumption rarely holds in real-world data.\n",
    "- Struggles with highly correlated features.\n",
    "- Performance depends heavily on the correct choice of variant (Gaussian, Bernoulli, Multinomial).\n",
    "- Multinomial and Bernoulli need non-negative/binary features, limiting flexibility.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4de67-fe6a-4f57-bba0-0e3587a8700d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5927371f-93da-4ff2-9568-b6d280333624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0ede0-cc3c-478a-b9fa-558aa510ed33",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc49e1d-bdda-4958-ad0d-edef60f69054",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\Arman\\Downloads\\dataset\\logit classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d16a5f-541d-4092-b513-a14e145dd784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8befe119-33c6-487b-8825-9d780afb75b5",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "### Split into features (X) and target (y)\n",
    "- X: Features (Age, EstimatedSalary)\n",
    "- y: Target (Purchased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad0d183-d76a-40a5-9dc4-99c4afb68484",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[[\"Age\", \"EstimatedSalary\"]].values\n",
    "y = dataset[\"Purchased\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed2299-e88f-4361-8109-db032043ad45",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842550a2-d137-4365-9d84-c05ae658798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1bf46c-b1bd-43d7-8934-a65f407b5763",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b11cc8-43f8-48fc-ba66-d2637174ddca",
   "metadata": {},
   "source": [
    "## Apply StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3be92ea-8507-4f0a-804e-a783b8986fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler() \n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40278c-b9ce-472d-9286-449c3cc168fc",
   "metadata": {},
   "source": [
    "## Apply NormalizerScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64c8ffb-c7b5-4e78-84c8-23df024c0084",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_norm = Normalizer()\n",
    "X_train_norm = sc_norm.fit_transform(X_train)\n",
    "X_test_norm = sc_norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b914b7-4706-4e37-947d-946c114f6773",
   "metadata": {},
   "source": [
    "## Training and Evaluating Navie Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea917518-e916-4338-b83f-d352ab4d1278",
   "metadata": {},
   "source": [
    "## BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c9685-f874-43d0-b951-35b9e0fc63b6",
   "metadata": {},
   "source": [
    "### With Scaling\n",
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aaade22-cfa7-42c9-9a89-86b64ee2e984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with StandardScaler\n",
      "Accuracy: 0.79\n",
      "Confusion Matrix:\n",
      " [[63  5]\n",
      " [16 16]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86        68\n",
      "           1       0.76      0.50      0.60        32\n",
      "\n",
      "    accuracy                           0.79       100\n",
      "   macro avg       0.78      0.71      0.73       100\n",
      "weighted avg       0.79      0.79      0.78       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier1 = BernoulliNB() \n",
    "classifier1.fit(X_train_sc, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred1 = classifier1.predict(X_test_sc)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"BernoulliNB with StandardScaler\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred1))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e88b1-b99e-48cc-bb33-2280df5211b7",
   "metadata": {},
   "source": [
    "#### NormalizerScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65375c60-ed16-485b-ac2c-530d76a90496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with NormalizerScaler\n",
      "Accuracy: 0.68\n",
      "Confusion Matrix:\n",
      " [[68  0]\n",
      " [32  0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        68\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.34      0.50      0.40       100\n",
      "weighted avg       0.46      0.68      0.55       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier2 = BernoulliNB() \n",
    "classifier2.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred2 = classifier2.predict(X_test_norm)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"BernoulliNB with NormalizerScaler\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred2))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred2))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e02c99-c388-45d7-b988-035020b11839",
   "metadata": {},
   "source": [
    "### Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e387a7-9436-4c9b-a9f8-32a747fccba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB without Scaling\n",
      "Accuracy: 0.68\n",
      "Confusion Matrix:\n",
      " [[68  0]\n",
      " [32  0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        68\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.34      0.50      0.40       100\n",
      "weighted avg       0.46      0.68      0.55       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier3 = BernoulliNB() \n",
    "classifier3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred3 = classifier3.predict(X_test)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"BernoulliNB without Scaling\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred3))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861de97-e6c1-45da-a0a2-e18e0e87cc7e",
   "metadata": {},
   "source": [
    "## GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a49582-aa54-4b91-9c0c-66c601b91fa8",
   "metadata": {},
   "source": [
    "### With Scaling\n",
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "806b88fb-1575-4540-9eb4-83de7c4a553d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB with StandardScaler\n",
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      " [[65  3]\n",
      " [ 7 25]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        68\n",
      "           1       0.89      0.78      0.83        32\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.90      0.87      0.88       100\n",
      "weighted avg       0.90      0.90      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier4 = GaussianNB() \n",
    "classifier4.fit(X_train_sc, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred4 = classifier4.predict(X_test_sc)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"GaussianNB with StandardScaler\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred4))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred4))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471227f-67c8-409e-ad8b-72e287198ae6",
   "metadata": {},
   "source": [
    "#### NormalizerScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "057b9f8a-bbb8-40f7-9f00-636abf7694dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB with NormalizerScaler\n",
      "Accuracy: 0.7\n",
      "Confusion Matrix:\n",
      " [[62  6]\n",
      " [24  8]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.81        68\n",
      "           1       0.57      0.25      0.35        32\n",
      "\n",
      "    accuracy                           0.70       100\n",
      "   macro avg       0.65      0.58      0.58       100\n",
      "weighted avg       0.67      0.70      0.66       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier5 = GaussianNB() \n",
    "classifier5.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred5 = classifier5.predict(X_test_norm)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"GaussianNB with NormalizerScaler\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred5))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred5))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885d1cd-09e5-4a28-937c-fa8eb57c823e",
   "metadata": {},
   "source": [
    "#### Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723655fb-ca21-4ed0-b6ad-e0603267dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB without Scaling\n",
      "Accuracy: 0.9\n",
      "Confusion Matrix:\n",
      " [[65  3]\n",
      " [ 7 25]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        68\n",
      "           1       0.89      0.78      0.83        32\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.90      0.87      0.88       100\n",
      "weighted avg       0.90      0.90      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier6 = GaussianNB() \n",
    "classifier6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred6 = classifier6.predict(X_test)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"GaussianNB without Scaling\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred6))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred6))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469a521-dc41-499d-bfdf-cdd539856fab",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0a9c9-3f50-4029-8cc3-baa748a31b1e",
   "metadata": {},
   "source": [
    "### With Scaling\n",
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb89ec9a-ede8-460f-8dd3-881ee9f03144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the  model on the Training set\n",
    "# classifier7 = MultinomialNB() \n",
    "# classifier7.fit(X_train_sc, y_train)\n",
    "\n",
    "# # Predicting the Test set results\n",
    "# y_pred7 = classifier7.predict(X_test_sc)\n",
    "\n",
    "# # Evaluation of the model\n",
    "# print(\"MultinomialNB with StandardScaler\")\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred7))\n",
    "# print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred7))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775459e2-bbb3-455c-beba-14bbf6270aba",
   "metadata": {},
   "source": [
    ">  **Note on MultinomialNB with StandardScaler:**\n",
    "\n",
    "MultinomialNB expects **non-negative feature values** (counts or frequencies). However, StandardScaler transforms features into z-scores (centered at 0), which produces **negative values** for below-average samples. Since negative inputs are invalid for MultinomialNB, this combination results in an error. To use MultinomialNB, features should remain as non-negative counts or be discretized into bins, not standardized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b05a6-e6a2-4a59-996f-f0560016c299",
   "metadata": {},
   "source": [
    "#### NormalizerScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b7374d4-99f6-4a40-b64c-9ff409ce6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB with NormalizerScaler\n",
      "Accuracy: 0.68\n",
      "Confusion Matrix:\n",
      " [[68  0]\n",
      " [32  0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        68\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.34      0.50      0.40       100\n",
      "weighted avg       0.46      0.68      0.55       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier8 = MultinomialNB() \n",
    "classifier8.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred8 = classifier8.predict(X_test_norm)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"MultinomialNB with NormalizerScaler\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred8))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred8))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088abbe-6869-4f89-9abf-f862a28622d6",
   "metadata": {},
   "source": [
    "### Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a084e417-e600-453e-9539-e50b6230b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB without Scaling\n",
      "Accuracy: 0.59\n",
      "Confusion Matrix:\n",
      " [[49 19]\n",
      " [22 10]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.71        68\n",
      "           1       0.34      0.31      0.33        32\n",
      "\n",
      "    accuracy                           0.59       100\n",
      "   macro avg       0.52      0.52      0.52       100\n",
      "weighted avg       0.58      0.59      0.58       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the  model on the Training set\n",
    "classifier9 = MultinomialNB() \n",
    "classifier9.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred9 = classifier9.predict(X_test)\n",
    "\n",
    "# Evaluation of the model\n",
    "print(\"MultinomialNB without Scaling\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred9))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred9))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61060a0-599a-4c91-af06-708fcfd2ac76",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparison of Naive Bayes Variants\n",
    "\n",
    "In this notebook, I explored three types of **Naive Bayes classifiers** — **BernoulliNB, GaussianNB, and MultinomialNB** — applied with different preprocessing techniques (no scaling, StandardScaler, Normalizer).\n",
    "\n",
    "**Key findings:**\n",
    "- **GaussianNB** performed the best (≈90% accuracy, strong precision/recall) both with and without StandardScaler. This makes sense since our features are continuous and roughly align with Gaussian assumptions.\n",
    "- **BernoulliNB** worked only with StandardScaler (≈79% accuracy). With no scaling or Normalizer, it predicted only the majority class (0), failing to identify positives. BernoulliNB is more suitable for binary features (after binarization).\n",
    "- **MultinomialNB** performed poorly on continuous features (best ≈68% accuracy by predicting only the majority class). It is designed for count/frequency data (e.g., text classification) rather than raw continuous values.\n",
    "- **Preprocessing impact:** StandardScaler improved or maintained performance, while Normalizer generally harmed results by distorting feature distributions.\n",
    "\n",
    "**Takeaways:**\n",
    "- For continuous numerical features → **GaussianNB** is the best choice.\n",
    "- BernoulliNB requires explicit binarization of features to be useful.\n",
    "- MultinomialNB should be applied to count-based data, not continuous features.\n",
    "- Always check confusion matrices and class-wise metrics, as accuracy alone can be misleading.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb80b3-9cf4-4fa3-a6ba-289ab91b9f93",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, I studied and implemented the **Naive Bayes Classifier**, a simple yet powerful probabilistic classification algorithm.  \n",
    "I explored the mathematical foundation starting with conditional probability, Bayes’ Theorem, and the working of the Naive Bayes algorithm.  \n",
    "I then applied three different variants of Naive Bayes — **GaussianNB, MultinomialNB, and BernoulliNB** — on the dataset under three scenarios:  \n",
    "- Without scaling  \n",
    "- With StandardScaler  \n",
    "- With Normalizer  \n",
    "\n",
    "Through experiments, I observed how each variant performs and how preprocessing techniques affect their accuracy. The results highlighted the importance of selecting the right variant based on data type and choosing appropriate preprocessing steps.  \n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "- **GaussianNB**:  \n",
    "  Works best for continuous data. Performance improves with scaling (StandardScaler/Normalizer) since it assumes normally distributed features.  \n",
    "\n",
    "- **MultinomialNB**:  \n",
    "  Suitable for count-based or frequency data (e.g., text classification).  \n",
    "  Does **not work with StandardScaler**, as scaling may introduce negative values, which violates its assumption of non-negative counts.  \n",
    "\n",
    "- **BernoulliNB**:  \n",
    "  Best for binary/boolean features.  \n",
    "  Scaling has minimal impact since it only considers whether a feature is present (1) or absent (0).  \n",
    "\n",
    "- **Scaling Matters**:  \n",
    "  GaussianNB is highly influenced by scaling, while BernoulliNB and MultinomialNB are relatively scale-invariant.  \n",
    "\n",
    "- **Practical Insight**:  \n",
    "  The choice of Naive Bayes variant should depend on the type of data (continuous, counts, or binary), and preprocessing should be applied carefully to avoid invalid inputs.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
