{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4f4d45-2699-4dc6-ada1-9eaad86db61b",
   "metadata": {},
   "source": [
    "# Day 52 – K-Nearest Neighbors (KNN) Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, I focus on **K-Nearest Neighbors (KNN) Classification**. KNN is a distance-based algorithm that predicts the class of a data point by looking at the majority class of its nearest neighbors.\n",
    "\n",
    "I begin with a short theory on how KNN works, why scaling is important, and the impact of choosing different `k` values. Then I implement KNN on a dataset, testing multiple `k` values (with and without scaling) to compare performance.\n",
    "\n",
    "By the end of this notebook, it becomes clear how scaling affects KNN, how accuracy changes with different `k`, and why selecting the right `k` is important for building a reliable classifier.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Classification?\n",
    "\n",
    "* **Classification** is a supervised learning technique where the goal is to predict the **category (class label)** of given input data.\n",
    "* Examples:\n",
    "\n",
    "  * Spam vs. Not Spam (emails)\n",
    "  * Disease vs. No Disease (medical test results)\n",
    "  * Will Buy vs. Will Not Buy (customer behavior)\n",
    "\n",
    "---\n",
    "\n",
    "## What is KNN Classification?\n",
    "\n",
    "The **K-Nearest Neighbors (KNN)** algorithm classifies a data point based on how its **neighbors** are classified.\n",
    "**K-Nearest Neighbors (KNN)** is a **non-parametric** and **lazy learning** algorithm.\n",
    "* **Non-parametric** means it makes no assumptions about the underlying data distribution.\n",
    "* **Lazy learning** means it doesn't build a model during the training phase. Instead, it \"memorizes\" the entire training dataset. The computation and learning only happen when a new data point needs a prediction.\n",
    "\n",
    "\n",
    "## How it Works: The Core Idea\n",
    "\n",
    "The fundamental principle of KNN is that \"similar things are near each other.\" To classify a new, unseen data point, the KNN algorithm follows these steps:\n",
    "\n",
    "1.  **Distance Calculation**: It calculates the distance between the new data point and every single point in the training dataset.\n",
    "   * Common distance metrics:\n",
    "     * Euclidean Distance\n",
    "     * Manhattan Distance\n",
    "     * Minkowski Distance\n",
    "\n",
    "3.  **Find the K-Nearest Neighbors**: It identifies the `K` data points that are closest to the new point (i.e., those with the smallest distances). The value of `K` is a hyperparameter you choose.\n",
    "4.  **Predict the Class**: For a classifier, the predicted class for the new data point is determined by a **majority vote** among its `K` nearest neighbors. The new data point is assigned the class that is most common among its neighbors.\n",
    "\n",
    "\n",
    "## Choosing a Hyperparameter `K`\n",
    "\n",
    "The choice of `K` is crucial and can significantly impact the model's performance:\n",
    "* **Small `K`** (e.g., K=1): The model is very sensitive to noise in the data, which can lead to **high variance** and **overfitting**.\n",
    "* **Large `K`**: The model becomes overly generalized and might miss fine-grained patterns, which can lead to **high bias** and **underfitting**.\n",
    "* Best `K` is usually found using **Cross Validation**.\n",
    "\n",
    "\n",
    "## Distance Metrics\n",
    "\n",
    "The choice of distance metric determines how the algorithm measures \"nearness.\" Some common metrics include:\n",
    "\n",
    "* **Euclidean Distance**: The most common metric. It calculates the shortest, straight-line distance between two points. It is the default in many implementations and works well with dense, continuous data.\n",
    "* **Manhattan Distance**: Also known as \"city block distance,\" it measures the distance by summing the absolute differences of the coordinates.\n",
    "* **Cosine Distance**: This metric measures the angle between two vectors and is particularly useful for high-dimensional data, such as in natural language processing (NLP) or when comparing documents, as it focuses on orientation rather than magnitude.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Characteristics\n",
    "\n",
    "* **No Training Phase**: The \"training\" phase for KNN is just storing the dataset.\n",
    "* **Feature Scaling is Crucial**: Since KNN relies on distance, features with larger scales can dominate the distance calculation. Therefore, **feature scaling (standardization or normalization)** is a vital preprocessing step for KNN.\n",
    "* **Computational Cost**: KNN can be computationally expensive for very large datasets, as it needs to calculate the distance to every data point for each new prediction.\n",
    "* **Simple and Interpretable**: The algorithm's logic is easy to understand, making its decisions highly interpretable.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages of KNN\n",
    "\n",
    "* Simple and intuitive.\n",
    "* Works well with smaller datasets.\n",
    "* No assumption about data distribution (non-parametric).\n",
    "\n",
    "## Limitations of KNN\n",
    "\n",
    "* **Computationally expensive** for large datasets (distance calculation for each prediction).\n",
    "* Sensitive to irrelevant features and feature scaling.\n",
    "* Choosing the right **value of K** is crucial.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Feature Scaling is Important in KNN?\n",
    "\n",
    "* KNN relies on **distance measures**.\n",
    "* Features with larger ranges dominate the distance calculation.\n",
    "* Example: Age (20–60) vs. Salary (30,000–150,000).\n",
    "* To fix this → apply **Normalization or Standardization** before KNN.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Metrics for Classification\n",
    "\n",
    "When evaluating KNN classification, common metrics include:\n",
    "\n",
    "* **Confusion Matrix**\n",
    "* **Accuracy Score**\n",
    "* **Precision, Recall, F1 Score**\n",
    "* **ROC-AUC Curve**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849cbd57-bf10-4794-a0a5-5a1eb4289da2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "573a880c-0a27-4fdb-9fa4-e7133b910888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001bb74d-1e2f-496b-bc1b-080dd6d77ab2",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f78706-fbf7-47a6-989a-31e4cf430235",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\Arman\\Downloads\\dataset\\logit classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf1c676-7974-43c7-95d2-d10b2bf0eb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe92fe-045a-487e-be35-350e1997935c",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Split into features (X) and target (y)\n",
    "- X: Features (Age, EstimatedSalary)\n",
    "- y: Target (Purchased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43212ca1-802e-453d-80ef-b862c34f133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[[\"Age\", \"EstimatedSalary\"]].values\n",
    "y = dataset[\"Purchased\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a37942-cd4c-41ca-bcaf-e8b4e00af716",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebba25f0-8f13-487b-b2a0-242b2c6f3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd18c54-ffa4-4b95-bc1e-0e4134e9a579",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "### Apply StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bead9a6-32c9-48e3-a4aa-27715d9c12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03d1a7a-f600-4617-95b3-9f578ee17fa4",
   "metadata": {},
   "source": [
    "## Train the KNN Model with different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c3108-f45f-4af5-a85c-3874cf3eb4f8",
   "metadata": {},
   "source": [
    "### Model 1: k=3, p=1 (Manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb6e498-db16-4176-903b-b0978c04e9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: k = 3, p = 1 (Manhattan) - 0.93\n",
      "Confusion Matrix of Model 1:\n",
      " [[64  4]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "model1 = KNeighborsClassifier(n_neighbors=3, p=1)\n",
    "model1.fit(X_train_sc, y_train)\n",
    "y_pred1 = model1.predict(X_test_sc)\n",
    "cm1 = confusion_matrix(y_test, y_pred1)\n",
    "print(\"Model 1: k = 3, p = 1 (Manhattan) -\", accuracy_score(y_test,y_pred1))\n",
    "print(\"Confusion Matrix of Model 1:\\n\", cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea908c-fbcd-479f-bf4b-c7318ccc97dd",
   "metadata": {},
   "source": [
    "### Model 2: k=4, p=1 (Manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8993f46d-b622-4c28-a96c-d0143d763967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2: k = 4, p = 1 (Manhattan) - 0.93\n",
      "Confusion Matrix of Model 2:\n",
      " [[64  4]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "model2 = KNeighborsClassifier(n_neighbors=4, p=1)\n",
    "model2.fit(X_train_sc, y_train)\n",
    "y_pred2 = model2.predict(X_test_sc)\n",
    "cm2 = confusion_matrix(y_test, y_pred2)\n",
    "print(\"Model 2: k = 4, p = 1 (Manhattan) -\", accuracy_score(y_test,y_pred2))\n",
    "print(\"Confusion Matrix of Model 2:\\n\", cm2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1491ecf-2972-4f50-8027-b4ff62755b53",
   "metadata": {},
   "source": [
    "### Model 3: k=5, p=1 (Manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9221682b-f75a-4f7a-aecf-587083e16c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3: k = 5, p = 1 (Manhattan) - 0.93\n",
      "Confusion Matrix of Model 3:\n",
      " [[64  4]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "model3 = KNeighborsClassifier(n_neighbors=5, p=1)\n",
    "model3.fit(X_train_sc, y_train)\n",
    "y_pred3 = model3.predict(X_test_sc)\n",
    "cm3 = confusion_matrix(y_test, y_pred3)\n",
    "print(\"Model 3: k = 5, p = 1 (Manhattan) -\", accuracy_score(y_test,y_pred3))\n",
    "print(\"Confusion Matrix of Model 3:\\n\", cm3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6c87c-227b-45ef-a35e-a69ae2c9af87",
   "metadata": {},
   "source": [
    "### Model 4: k=3, p=2 (Euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d84750f4-702d-43ee-8f12-c20a0618eb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4: k = 3, p = 2 (Euclidean) - 0.93\n",
      "Confusion Matrix of Model 4:\n",
      " [[64  4]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "model4 = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "model4.fit(X_train_sc, y_train)\n",
    "y_pred4 = model4.predict(X_test_sc)\n",
    "cm4 = confusion_matrix(y_test, y_pred4)\n",
    "print(\"Model 4: k = 3, p = 2 (Euclidean) -\", accuracy_score(y_test,y_pred4))\n",
    "print(\"Confusion Matrix of Model 4:\\n\", cm4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6640fb-7507-4948-80e7-f03abce623f2",
   "metadata": {},
   "source": [
    "### Model 5: k=4, p=2 (Euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d983460-45cb-4ef5-b0ca-73bbaae36834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5: k = 4, p = 2 (Euclidean) - 0.92\n",
      "Confusion Matrix of Model 5:\n",
      " [[64  4]\n",
      " [ 4 28]]\n"
     ]
    }
   ],
   "source": [
    "model5 = KNeighborsClassifier(n_neighbors=4, p=2)\n",
    "model5.fit(X_train_sc, y_train)\n",
    "y_pred5 = model5.predict(X_test_sc)\n",
    "cm5 = confusion_matrix(y_test, y_pred5)\n",
    "print(\"Model 5: k = 4, p = 2 (Euclidean) -\", accuracy_score(y_test,y_pred5))\n",
    "print(\"Confusion Matrix of Model 5:\\n\", cm5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4a1b3-adf9-42a2-acc5-55c2c2f5cd56",
   "metadata": {},
   "source": [
    "### Model 6: k=5, p=2 (Euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3266e0c2-c236-406f-8eab-178ab96c1c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6: k = 5, p = 2 (Euclidean) - 0.93\n",
      "Confusion Matrix of Model 6:\n",
      " [[64  4]\n",
      " [ 3 29]]\n"
     ]
    }
   ],
   "source": [
    "model6 = KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "model6.fit(X_train_sc, y_train)\n",
    "y_pred6 = model6.predict(X_test_sc)\n",
    "cm6 = confusion_matrix(y_test, y_pred6)\n",
    "print(\"Model 6: k = 5, p = 2 (Euclidean) -\", accuracy_score(y_test,y_pred6))\n",
    "print(\"Confusion Matrix of Model 6:\\n\", cm6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30123fb3-9e90-466a-9a92-a359122243a4",
   "metadata": {},
   "source": [
    "### Without Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c33a570-6063-4a96-a069-8781a9cb5381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 0.78\n",
      "Confusion Matrix of Model 7:\n",
      " [[57 11]\n",
      " [11 21]]\n"
     ]
    }
   ],
   "source": [
    "model7 = KNeighborsClassifier(n_neighbors = 3, p=1)\n",
    "model7.fit(X_train, y_train)\n",
    "y_pred7 = model7.predict(X_test)\n",
    "cm7 = confusion_matrix(y_test, y_pred7)\n",
    "print(\"Accuracy without scaling:\", accuracy_score(y_test, y_pred7))\n",
    "print(\"Confusion Matrix of Model 7:\\n\", cm7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83a776-f567-40cb-b71f-3880ccf23864",
   "metadata": {},
   "source": [
    "## Results Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c601744-3af0-4aab-be2f-fced3887b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparision Table:\n",
      "\n",
      "                 Model  k  Distance Metric (p)  Accuracy\n",
      "0                    1  3                    1      0.93\n",
      "1                    2  4                    1      0.93\n",
      "2                    3  5                    1      0.93\n",
      "3                    4  3                    2      0.93\n",
      "4                    5  4                    2      0.92\n",
      "5                    6  5                    2      0.93\n",
      "6  (Without Scaling) 7  3                    1      0.78\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"(Without Scaling) 7\"],\n",
    "    \"k\": [3,4,5,3,4,5,3],\n",
    "    \"Distance Metric (p)\": [1,1,1,2,2,2,1],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, y_pred1),\n",
    "        accuracy_score(y_test, y_pred2),\n",
    "        accuracy_score(y_test, y_pred3),\n",
    "        accuracy_score(y_test, y_pred4),\n",
    "        accuracy_score(y_test, y_pred5),\n",
    "        accuracy_score(y_test, y_pred6),\n",
    "        accuracy_score(y_test, y_pred7)]})\n",
    "\n",
    "print(\"Comparision Table:\\n\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f809ae4-250d-437b-bde6-bc362d4ad54b",
   "metadata": {},
   "source": [
    "## Comparison of K Values\n",
    "\n",
    "| **K Value / Condition**  | **Accuracy** | **Confusion Matrix**    | **Interpretation**                                                                                                                                                                                   |\n",
    "| ------------------------ | ------------ | ----------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **k = 3 (with scaling)** | **0.93**     | \\[\\[64, 4], \\[ 3, 29]]  | Very good accuracy. The model correctly classifies most samples with only a few false positives and false negatives. With k=3, the boundary is flexible but scaling helps keep noise under control.  |\n",
    "| **k = 4 (with scaling)** | **0.93**     | \\[\\[64, 4], \\[ 3, 29]]  | Accuracy remains the same as k=3. The confusion matrix is also identical, meaning both values perform equally well in this case.                                                                     |\n",
    "| **k = 5 (with scaling)** | **0.93**     | \\[\\[64, 4], \\[ 3, 29]]  | Again, accuracy is stable at 0.93. This shows the model is not very sensitive to small changes in k around this range. Choosing k=5 usually balances bias and variance, so it is a safe choice.      |\n",
    "| **k = 3 (no scaling)**   | **0.78**     | \\[\\[57, 11], \\[11, 21]] | Accuracy drops significantly without scaling. Larger–range features dominate the distance calculation, leading to poor classification. This highlights the importance of **feature scaling in KNN**. |\n",
    "\n",
    "\n",
    "## Key Observations\n",
    "\n",
    "* With scaling, **k=3, 4, and 5 all give excellent accuracy (0.93)**, showing stability in this range.\n",
    "* Without scaling, accuracy drops to **0.78**, clearly proving that scaling is **crucial for distance-based algorithms** like KNN.\n",
    "* A middle value such as **k=5** is generally preferred since it balances flexibility (low bias) and stability (low variance).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a2eed-66e6-4aa6-8a6a-da4ee354caec",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Implemented KNN with **k = 3, 4, 5 (with scaling)** → all achieved accuracy of **0.93**.\n",
    "* Using **k = 3 without scaling** dropped accuracy to **0.78**, proving that scaling is crucial.\n",
    "* Confusion matrices confirmed differences in misclassifications across experiments.\n",
    "* KNN was found stable for multiple `k` values, but scaling significantly improved results.\n",
    "\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "* KNN is **distance-based** and sensitive to feature scaling.\n",
    "* Small `k` → flexible, risk of overfitting; larger `k` → smoother, risk of underfitting.\n",
    "* **Scaling features is mandatory** for good KNN performance.\n",
    "* Best accuracy achieved in this notebook: **0.93 (scaled data, k=3–5)**.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
