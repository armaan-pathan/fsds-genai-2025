{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a482fb3d-bb27-465c-b565-c854e0001801",
   "metadata": {},
   "source": [
    "# Day 23 – Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) is the process of examining, visualizing, and preparing raw data before applying any machine learning model or statistical technique.\n",
    "\n",
    "EDA helps to:\n",
    "- Understand the structure, trends, and patterns in the data\n",
    "- Detect missing values, outliers, and anomalies\n",
    "- Discover relationships between variables\n",
    "- Guide feature engineering and model selection\n",
    "\n",
    "---\n",
    "\n",
    "## 1. What is Raw Data?\n",
    "\n",
    "Raw data is the initial form of data collected from various sources like surveys, sensors, logs, web scraping, etc.\n",
    "\n",
    "It often contains:\n",
    "- Missing values\n",
    "- Inconsistent formats\n",
    "- Duplicates\n",
    "- Irrelevant features\n",
    "- Mixed data types\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Cleaning\n",
    "\n",
    "Data cleaning involves correcting or removing inaccurate, corrupted, or incomplete data.\n",
    "\n",
    "Common tasks include:\n",
    "- Handling missing values\n",
    "- Fixing inconsistent data types\n",
    "- Removing duplicate rows\n",
    "- Filling in or dropping nulls\n",
    "- Renaming columns for clarity\n",
    "\n",
    "Cleaning ensures the dataset is ready for analysis and modeling.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Variable Identification\n",
    "\n",
    "Identifying the role of each column helps shape the direction of analysis and modeling.\n",
    "\n",
    "| Type               | Description                            | Examples            |\n",
    "|--------------------|-----------------------------------------|---------------------|\n",
    "| Independent (IV)   | Input features                          | Age, Salary, Gender |\n",
    "| Dependent (DV)     | Output/target variable                  | Purchased, Outcome  |\n",
    "\n",
    "Example:  \n",
    "If you're predicting whether someone will buy a product, the input features like `Age`, `Income`, etc., are IVs and the `WillBuy` column is the DV.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Univariate Analysis\n",
    "\n",
    "This type of analysis focuses on a single variable at a time.\n",
    "\n",
    "For **numerical variables**:\n",
    "- Histogram\n",
    "- Boxplot\n",
    "- KDE (Kernel Density Estimation)\n",
    "\n",
    "For **categorical variables**:\n",
    "- Count plot\n",
    "- Pie chart\n",
    "\n",
    "Univariate analysis helps understand the distribution and frequency of values.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Bivariate Analysis\n",
    "\n",
    "Bivariate analysis studies the relationship between two variables.\n",
    "\n",
    "Common comparisons:\n",
    "- Numerical vs Numerical → Scatter plot, Correlation\n",
    "- Categorical vs Numerical → Boxplot, Barplot\n",
    "- Categorical vs Categorical → Grouped barplot, Crosstab\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Correlation\n",
    "\n",
    "Correlation measures the strength and direction of a linear relationship between two numeric variables.\n",
    "\n",
    "| Correlation Value | Meaning                |\n",
    "|-------------------|------------------------|\n",
    "| 1                 | Perfect positive       |\n",
    "| 0                 | No correlation         |\n",
    "| -1                | Perfect negative       |\n",
    "\n",
    "Important for feature selection, multicollinearity checks, and relationship understanding.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Outlier Detection\n",
    "\n",
    "Outliers are unusual data points that differ significantly from others.\n",
    "\n",
    "Common detection methods:\n",
    "- Boxplot\n",
    "- Z-score\n",
    "- IQR method\n",
    "\n",
    "Outliers can:\n",
    "- Skew statistical summaries\n",
    "- Mislead machine learning models\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Feature Engineering\n",
    "\n",
    "Feature engineering involves transforming or creating new features to improve model performance.\n",
    "\n",
    "Key techniques:\n",
    "- Label encoding / One-hot encoding\n",
    "- Creating dummy variables\n",
    "- Binning numeric data (e.g. age groups)\n",
    "- Generating interaction terms\n",
    "\n",
    "This step is crucial for preparing categorical and continuous variables for ML models.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. EDA Process Overview\n",
    "\n",
    "Step-by-step EDA approach:\n",
    "\n",
    "1. Load the dataset\n",
    "2. Explore dataset dimensions and types\n",
    "3. Handle missing values and duplicates\n",
    "4. Identify variable roles (IV/DV)\n",
    "5. Conduct univariate and bivariate analysis\n",
    "6. Visualize relationships and distributions\n",
    "7. Create new features if needed\n",
    "8. Finalize clean dataset for modeling\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "EDA is a **critical pre-modeling step** in any data science project. It provides insights into the structure, quality, and characteristics of the dataset, which directly impacts model accuracy and interpretability.\n",
    "\n",
    "**Libraries commonly used in EDA:**\n",
    "- `pandas` – data handling\n",
    "- `numpy` – numerical operations\n",
    "- `matplotlib` & `seaborn` – visualizations\n",
    "- `scipy` – statistical tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df105fb5-aaa8-49b5-8bc2-59facf80d18a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Introduction to Machine Learning (Post-EDA)\n",
    "\n",
    "Once you've completed data cleaning and exploratory data analysis (EDA), the next step is to apply machine learning models to draw predictions and patterns from your data.\n",
    "\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "Supervised learning uses **labeled data** (i.e., input features + target output) to train a model.\n",
    "\n",
    "There are two major types:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Regression\n",
    "\n",
    "Regression is used when the **target variable (dependent variable) is continuous** (numeric).\n",
    "\n",
    "### Common Regression Algorithms:\n",
    "1. Simple Linear Regression  \n",
    "2. Multiple Linear Regression  \n",
    "3. Gradient Descent Variants:  \n",
    "   - Batch Gradient Descent (BGD)  \n",
    "   - Stochastic Gradient Descent (SGD)  \n",
    "4. Lasso & Ridge (L1 & L2 Regularization)  \n",
    "5. K-Nearest Neighbor Regressor (KNN)  \n",
    "6. Support Vector Regressor (SVR)  \n",
    "7. Decision Tree Regressor (DTR)  \n",
    "8. XGBoost Regressor (XGB)  \n",
    "9. LightGBM Regressor (LGB)  \n",
    "10. Artificial Neural Network (ANN) Regressor  \n",
    "11. Time Series Forecasting  \n",
    "12. Random Forest Regressor\n",
    "\n",
    "Use regression when your output is something like **price, score, distance, revenue**, etc.\n",
    "\n",
    "### Examples:\n",
    "- Predicting house price\n",
    "- Forecasting stock price\n",
    "- Estimating salary based on experience\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Classification\n",
    "\n",
    "Classification is used when the **target variable is categorical** (labels or classes).\n",
    "\n",
    "### Common Classification Algorithms:\n",
    "1. Logistic Regression  \n",
    "2. Support Vector Machine (SVM)  \n",
    "3. K-Nearest Neighbor Classifier (KNN)  \n",
    "4. Naive Bayes (Bayesian Theorem)  \n",
    "5. Decision Tree Classifier  \n",
    "6. Random Forest Classifier  \n",
    "7. Ensemble Learning Techniques  \n",
    "8. XGBoost Classifier  \n",
    "9. LightGBM Classifier  \n",
    "10. Artificial Neural Network (ANN) Classifier\n",
    "\n",
    "Use classification when your output is like **yes/no, spam/ham, pass/fail, disease/no disease**, etc.\n",
    "\n",
    "### Examples:\n",
    "- Spam vs Not Spam\n",
    "- Disease vs No Disease\n",
    "- Will Buy vs Won’t Buy\n",
    "\n",
    "---\n",
    "\n",
    "## Regression vs Classification\n",
    "\n",
    "| Feature              | Regression                  | Classification             |\n",
    "|----------------------|-----------------------------|-----------------------------|\n",
    "| Target Variable Type | Continuous (numeric)        | Categorical (labels/classes)|\n",
    "| Output Example       | Price, Score, Temp          | Yes/No, Spam/Not, Category  |\n",
    "| Evaluation Metric    | MAE, MSE, RMSE, R² Score    | Accuracy, F1 Score, AUC     |\n",
    "| Sample Algorithm     | Linear Regression           | Logistic Regression         |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Unsupervised Learning – Clustering\n",
    "\n",
    "While regression and classification are types of **supervised learning**, clustering belongs to a different category called **unsupervised learning**.\n",
    "\n",
    "In unsupervised learning, the dataset has **no labeled output**. The goal is to discover **hidden patterns or natural groupings** in the data.\n",
    "\n",
    "---\n",
    "\n",
    "## What is Clustering?\n",
    "\n",
    "Clustering is a technique used to **group similar data points together** based on their features, similarity, without knowing the target variable in advance.\n",
    "\n",
    "### Common Clustering Techniques:\n",
    "1. Principal Component Analysis (PCA) – Dimensionality reduction & grouping  \n",
    "2. K-Means Clustering  \n",
    "3. Hierarchical Clustering  \n",
    "4. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "\n",
    "Use clustering when you're doing:\n",
    "- Customer segmentation  \n",
    "- Anomaly detection  \n",
    "- Pattern discovery without predefined categories\n",
    "\n",
    "\n",
    "### Real-World Examples:\n",
    "- Grouping customers by purchasing behavior\n",
    "- Organizing news articles by topics\n",
    "- Segmenting users by browsing activity\n",
    "- Detecting fraudulent transactions\n",
    "\n",
    "Clustering is especially useful when you want to **explore structure** in the data or **segment** it for targeted analysis before applying supervised techniques.\n",
    "\n",
    "---\n",
    "# Summary Table\n",
    "\n",
    "| Task Type       | Target Variable | Algorithms Example                   |\n",
    "|------------------|------------------|--------------------------------------|\n",
    "| Regression        | Continuous       | Linear Regression, XGBoost, ANN      |\n",
    "| Classification    | Categorical      | Logistic Regression, SVM, RF, ANN    |\n",
    "| Clustering        | Not available    | K-Means, PCA, DBSCAN                 |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
