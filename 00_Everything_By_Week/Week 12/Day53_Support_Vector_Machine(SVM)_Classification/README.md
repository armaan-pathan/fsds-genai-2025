# Day 53 â€“ Support Vector Machine (SVM) Classifier

## Overview

On Day 53, I studied the **Support Vector Machine (SVM) Classifier**, a supervised machine learning algorithm widely used for classification tasks. This notebook combines both **theoretical explanation** and **practical implementation** to build a solid understanding of SVM.

---

## Topics Covered

* Introduction to **SVM and its working principle**

  * Hyperplanes, margins, and support vectors
  * The **kernel trick** for handling non-linear data
* Implementing SVM model
* Applying **feature scaling** for better performance
* Training the SVM model and evaluating results with:

  * Accuracy
  * Confusion Matrix
  * Classification Report
* Making **future predictions** with the trained model

---

## Key Learnings

* SVM constructs an **optimal decision boundary** by maximizing the margin.
* **Support vectors** are the most important points that define this boundary.
* The **kernel trick** enables SVM to solve complex, non-linear classification problems.
* Proper **feature scaling** is necessary for SVM to perform effectively.
* Evaluation metrics such as **accuracy, confusion matrix, and classification report** help in analyzing performance.
* SVM can be applied for both **binary and multi-class problems** but may be computationally heavy for very large datasets.
* The trained model can be extended to make **predictions on future/unseen data**.

---

## Conclusion

Day 53 helped me understand how SVM works both in **theory and practice**. I learned not just how to train and evaluate an SVM model but also how kernels expand its capabilities to handle more complex datasets. By the end of this notebook, I was able to make predictions on unseen data, reinforcing the importance of SVM as a powerful classification tool.
