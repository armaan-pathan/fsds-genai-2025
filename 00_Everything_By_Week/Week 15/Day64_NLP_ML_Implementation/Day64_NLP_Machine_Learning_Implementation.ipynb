{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4dfdbd-17df-4219-88dc-79812c2d03c2",
   "metadata": {},
   "source": [
    "# Day 64 – How Machine Learning Models are Implemented in NLP\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Today, I'll explore how **Machine Learning (ML)** techniques can be applied to **Natural Language Processing (NLP)** tasks.\n",
    "NLP allows computers to understand and analyze human language, and ML provides the intelligence that helps make predictions and decisions based on textual data.\n",
    "\n",
    "In this notebook, I'll work with a **Restaurant Reviews dataset** to predict whether a customer review is **positive** or **negative**.\n",
    "I'll apply traditional ML models to perform **sentiment analysis**, which helps understand customer opinions and feedback automatically.\n",
    "\n",
    "By the end of this session, I’ll understand how NLP data flows through a typical ML pipeline — from text preprocessing to model evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. NLP + ML Pipeline Overview\n",
    "\n",
    "Implementing an NLP task using Machine Learning involves several key steps, which together form a complete **ML workflow**.\n",
    "Here’s an overview of the **NLP + ML pipeline**:\n",
    "\n",
    "### Step 1: Import Libraries and Dataset\n",
    "\n",
    "Import essential libraries such as:\n",
    "\n",
    "* `pandas`, `numpy` – for data handling and analysis.\n",
    "* `matplotlib`, `seaborn` – for visualization.\n",
    "* `sklearn` – for ML model building and evaluation.\n",
    "* `nltk` or `re` – for text preprocessing.\n",
    "\n",
    "Load the **Restaurant Reviews dataset** using `pandas.read_csv()` or any data source.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Text Cleaning and Preprocessing\n",
    "\n",
    "Before feeding text data into a model, it must be cleaned and standardized.\n",
    "Common preprocessing steps include:\n",
    "\n",
    "1. **Removing punctuation, numbers, and special characters.**\n",
    "2. **Converting all text to lowercase.**\n",
    "3. **Removing stopwords** (like “is”, “the”, “and”) that don’t add much meaning.\n",
    "4. **Stemming or Lemmatization** – reducing words to their base or root form (e.g., “loved” → “love”).\n",
    "\n",
    "This step helps convert messy text into structured, meaningful data that ML models can interpret.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Feature Extraction\n",
    "\n",
    "ML models can’t understand raw text — so we must convert it into numerical features.\n",
    "This process is called **vectorization** or **feature extraction**.\n",
    "\n",
    "Common methods:\n",
    "\n",
    "* **Bag of Words (BoW):** Counts how often each word appears.\n",
    "* **TF-IDF (Term Frequency–Inverse Document Frequency):** Weighs words by their importance in a document relative to the corpus.\n",
    "\n",
    "The result is a **sparse matrix** where each row represents a review and each column represents a word feature.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Splitting the Dataset\n",
    "\n",
    "Split the dataset into:\n",
    "\n",
    "* **Training set:** Used to train the ML model (usually 70–80% of data).\n",
    "* **Testing set:** Used to evaluate model performance (20–30% of data).\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Training Machine Learning Models\n",
    "\n",
    "- Train different ML models to classify the sentiment\n",
    "- Each model learns patterns from the training data and builds decision boundaries to predict sentiments.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 6: Model Evaluation\n",
    "\n",
    "After training, evaluate model performance using:\n",
    "\n",
    "* **Accuracy Score** – measures how often the model is correct.\n",
    "* **Confusion Matrix (CM)** – shows how many reviews were correctly and incorrectly classified.\n",
    "* **Classification Report** – includes precision, recall, and F1-score.\n",
    "\n",
    "These metrics help determine whether the model is performing well or needs improvements.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 7: Result Comparison and Insights\n",
    "\n",
    "Compare all models based on accuracy and confusion matrices.\n",
    "This helps identify which model performs best for your dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 8: Insights and Conclusion\n",
    "\n",
    "* Identify which model achieves the best accuracy.\n",
    "* Analyze common misclassifications using the confusion matrix.\n",
    "* Observe whether the model shows **bias** (predicts one class more often) or **variance** (performs inconsistently).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a3332-e7d8-40dd-ab42-0ae6e2eb7e29",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5525ba08-f3fb-4500-9f47-d0a9971ad8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331df03-b0df-4278-90c0-fcc8520efccd",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e25b2a-8a27-42f5-a09e-ef0686d59a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r\"C:\\Users\\Arman\\Downloads\\dataset\\Restaurant_Reviews.tsv\", delimiter = '\\t', quoting = 3)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7be37-bf8e-4744-a19c-aff0637ef5fe",
   "metadata": {},
   "source": [
    "## Text Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08bddf69-ec31-4697-b994-72721559afe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wow love place',\n",
       " 'crust good',\n",
       " 'tasti textur nasti',\n",
       " 'stop late may bank holiday rick steve recommend love',\n",
       " 'select menu great price',\n",
       " 'get angri want damn pho',\n",
       " 'honeslti tast fresh',\n",
       " 'potato like rubber could tell made ahead time kept warmer',\n",
       " 'fri great',\n",
       " 'great touch',\n",
       " 'servic prompt',\n",
       " 'would go back',\n",
       " 'cashier care ever say still end wayyy overpr',\n",
       " 'tri cape cod ravoli chicken cranberri mmmm',\n",
       " 'disgust pretti sure human hair']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus = []  \n",
    "\n",
    "for i in range(0, 1000):\n",
    "    # Keep only letters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n",
    "    # Lowercase\n",
    "    review = review.lower()\n",
    "    # Tokenize\n",
    "    review = review.split()\n",
    "    # Stemming + Stopword Removal\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    # Join back into string\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "corpus[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d49e0-acae-4138-801b-511cb210ac4d",
   "metadata": {},
   "source": [
    "## Feature Extraction (Creating the Bag of Words model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a35ac91-1fae-4517-b058-a1116a7b7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=1500)   \n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9360e6f-3bf7-4a5e-9c9a-102d5793c932",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f0c46d-f9af-471d-a478-b78f5490dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13156fcd-1c64-469a-a157-73ba10849154",
   "metadata": {},
   "source": [
    "## Train Machine Learning Model (Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0091eccb-0655-4d0b-9e9a-6bfb58edac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed9efb-208c-4a66-8029-62d6f11e43a3",
   "metadata": {},
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7057d13a-f189-468e-881a-2cbb22b394e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[71 26]\n",
      " [38 65]]\n",
      "Accuracy: 0.68\n",
      "Bias (Training Score): 0.99625\n",
      "Variance (Test Score): 0.68\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix & Accuracy\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", ac)\n",
    "\n",
    "# Bias & Variance\n",
    "bias = classifier.score(X_train,y_train)\n",
    "variance = classifier.score(X_test,y_test)\n",
    "print(\"Bias (Training Score):\", bias)\n",
    "print(\"Variance (Test Score):\", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197ea07-8d32-4e3d-858f-e768ac9d2bf5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Results Interpretation\n",
    "\n",
    "### Confusion Matrix\n",
    "\n",
    "The confusion matrix summarizes how well the model classified positive and negative reviews.\n",
    "\n",
    "* **True Positives (TP = 71)** → Positive reviews correctly identified as positive.\n",
    "* **True Negatives (TN = 65)** → Negative reviews correctly identified as negative.\n",
    "* **False Positives (FP = 26)** → Negative reviews wrongly predicted as positive.\n",
    "* **False Negatives (FN = 38)** → Positive reviews wrongly predicted as negative.\n",
    "\n",
    "The model appears to perform slightly **better at detecting negative reviews** than positive ones, as seen from the higher number of correctly predicted negatives.\n",
    "\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "The model’s accuracy gives an overall idea of how many predictions were correct out of all predictions made.\n",
    "\n",
    "$$ \n",
    "Accuracy = \\frac{TP + TN}{Total} = \\frac{71 + 65}{200} = 0.68\n",
    "$$ \n",
    "\n",
    "* The model achieved an **accuracy of 68%**, which indicates a moderate level of performance.\n",
    "* While it can distinguish between positive and negative reviews to some extent, there’s still plenty of room for improvement.\n",
    "\n",
    "\n",
    "### Bias (Training Score) → **0.99625**\n",
    "\n",
    "* The model performs almost perfectly on training data, scoring around **99.6%**.\n",
    "* This means it has learned the training examples extremely well — possibly **too well** — which is often a warning sign that the model is not generalizing properly.\n",
    "\n",
    "### Variance (Test Score) → **0.68**\n",
    "\n",
    "* When tested on unseen data, the performance drops sharply to **68%**.\n",
    "* This gap between training and test accuracy clearly shows the model’s tendency to **memorize training data** rather than learning general patterns.\n",
    "\n",
    "\n",
    "### Diagnosis\n",
    "\n",
    "* The large difference between training and test performance indicates **overfitting (high variance)**.\n",
    "* The model has become too specific to the training data, capturing noise instead of meaningful insights.\n",
    "* As a result, it performs well during training but struggles to handle new, unseen examples.\n",
    "\n",
    "---\n",
    "\n",
    "## Improving Model Accuracy\n",
    "\n",
    "Since the Decision Tree model currently achieves around **68% accuracy**, it needs optimization to reach a more reliable performance level.\n",
    "\n",
    "To improve results, the following steps should be taken:\n",
    "\n",
    "1. **Experiment with multiple classification models** such as Logistic Regression, Naïve Bayes, Random Forest, and SVM.\n",
    "2. **Maintain the same train/test split** to ensure that all models are compared under identical conditions.\n",
    "3. **Compare accuracy and confusion matrices** across different algorithms to identify the best performer.\n",
    "4. **Tune hyperparameters** using techniques like Grid Search or Random Search to find the optimal model settings.\n",
    "\n",
    "**Target:** Achieve at least **80% accuracy** while reducing the gap between training and test performance — ensuring the model generalizes well and avoids overfitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e719930-0368-4b08-865c-d00f805d4b72",
   "metadata": {},
   "source": [
    "## Import different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90977e3d-dff0-47a3-89f8-04c78922c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Store models in dictionary\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0, max_depth=10),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d3461-fd3f-4673-a529-49c9195dcd9b",
   "metadata": {},
   "source": [
    "## Train and evaluate each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d57d0751-8647-476d-ba3b-5ac904591a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decision Tree\n",
      "Accuracy: 0.69\n",
      "Confusion Matrix:\n",
      " [[94  3]\n",
      " [59 44]]\n",
      "\n",
      " Naive Bayes\n",
      "Accuracy: 0.765\n",
      "Confusion Matrix:\n",
      " [[72 25]\n",
      " [22 81]]\n",
      "\n",
      " Logistic Regression\n",
      "Accuracy: 0.71\n",
      "Confusion Matrix:\n",
      " [[76 21]\n",
      " [37 66]]\n",
      "\n",
      " Random Forest\n",
      "Accuracy: 0.715\n",
      "Confusion Matrix:\n",
      " [[86 11]\n",
      " [46 57]]\n",
      "\n",
      " SVM (Linear)\n",
      "Accuracy: 0.72\n",
      "Confusion Matrix:\n",
      " [[76 21]\n",
      " [35 68]]\n",
      "\n",
      " SVM (RBF)\n",
      "Accuracy: 0.73\n",
      "Confusion Matrix:\n",
      " [[90  7]\n",
      " [47 56]]\n",
      "\n",
      " KNN\n",
      "Accuracy: 0.63\n",
      "Confusion Matrix:\n",
      " [[83 14]\n",
      " [60 43]]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results[name] = acc\n",
    "    \n",
    "    print(f\"\\n {name}\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccabdc2-902e-4eb3-a450-5cea222acb64",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "700f828b-58c0-4a0c-be91-923ef2755212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "1          Naive Bayes     0.765\n",
       "5            SVM (RBF)     0.730\n",
       "4         SVM (Linear)     0.720\n",
       "3        Random Forest     0.715\n",
       "2  Logistic Regression     0.710\n",
       "0        Decision Tree     0.690\n",
       "6                  KNN     0.630"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare results\n",
    "results_df = pd.DataFrame(list(results.items()), columns=[\"Model\", \"Accuracy\"])\n",
    "results_df = results_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff5329-5e06-4da0-a521-b97005a55868",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "* **Naive Bayes** performed the best with an accuracy of **76.5%**, showing that it handles text data effectively using **Bag-of-Words** or **TF-IDF** features.\n",
    "* **SVM (RBF and Linear)** came close, achieving around **72–73%**, indicating strong generalization but slightly lower accuracy than Naive Bayes.\n",
    "* **Random Forest** and **Logistic Regression** achieved **71–72%**, offering stable but moderate performance.\n",
    "* **Decision Tree** reached **69%**, confirming that it overfits easily and fails to generalize well.\n",
    "* **KNN** scored **63%**, the lowest among all models, as distance-based methods struggle with high-dimensional text data.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* The initial **Decision Tree model (68%)** showed overfitting and limited accuracy, but experimenting with multiple algorithms led to a significant improvement.\n",
    "* **Naive Bayes (76.5%)** emerged as the most efficient and consistent model for this sentiment classification task.\n",
    "* Although accuracy improved, the target of **80%** has not yet been reached — further optimization such as **hyperparameter tuning**, **feature engineering**, and **ensemble techniques** can help boost model performance beyond this threshold.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb6284-b00f-4835-ac61-de11e68908dc",
   "metadata": {},
   "source": [
    "## Build the Model with TF-IDF Vectorizer\n",
    "\n",
    "Up to this point, I used the **Bag of Words (CountVectorizer)** approach, which simply counts how many times each word appears in a review.\n",
    "While effective, it doesn’t take into account how **important** or **unique** a word is across the entire dataset.\n",
    "\n",
    "To improve this, I'll now use **TF-IDF (Term Frequency – Inverse Document Frequency)**, which provides a better way of representing text data numerically.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "* **Term Frequency (TF):**\n",
    "  Measures how frequently a word appears in a single document (review).\n",
    "  The more times a word appears, the higher its TF value.\n",
    "\n",
    "* **Inverse Document Frequency (IDF):**\n",
    "  Measures how rare or unique a word is across all documents.\n",
    "  Common words like *“the”*, *“is”*, and *“a”* get a **lower IDF score**, while rare and meaningful words like *“delicious”* or *“terrible”* get **higher scores**.\n",
    "\n",
    "* **TF-IDF Value:**\n",
    "  Combines both TF and IDF to highlight **important and distinctive words** in each review while reducing the impact of common or irrelevant ones.\n",
    "\n",
    "### Why Use TF-IDF?\n",
    "\n",
    "Unlike the simple word count method, TF-IDF focuses on **word importance rather than frequency**, making it more powerful for classification tasks.\n",
    "This generally leads to **better model accuracy and generalization**, especially for algorithms like **Logistic Regression**, **SVM**, and **Naïve Bayes**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e3c3c-92d4-4f3a-bbec-daa87bb06d5e",
   "metadata": {},
   "source": [
    "## Import models aain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19f95c3e-5a31-46da-bfd7-5fe106e82386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define models\n",
    "models_tfidf = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=0, max_depth=10),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results_tfidf = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb55ea-9794-4398-a00e-12feeed1611a",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23a8a859-8ce0-4018-865f-062020fcd50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Decision Tree\n",
      "Accuracy: 0.69\n",
      "Confusion Matrix:\n",
      " [[94  3]\n",
      " [59 44]]\n",
      "\n",
      " Naive Bayes\n",
      "Accuracy: 0.765\n",
      "Confusion Matrix:\n",
      " [[72 25]\n",
      " [22 81]]\n",
      "\n",
      " Logistic Regression\n",
      "Accuracy: 0.71\n",
      "Confusion Matrix:\n",
      " [[76 21]\n",
      " [37 66]]\n",
      "\n",
      " Random Forest\n",
      "Accuracy: 0.715\n",
      "Confusion Matrix:\n",
      " [[86 11]\n",
      " [46 57]]\n",
      "\n",
      " SVM (Linear)\n",
      "Accuracy: 0.72\n",
      "Confusion Matrix:\n",
      " [[76 21]\n",
      " [35 68]]\n",
      "\n",
      " SVM (RBF)\n",
      "Accuracy: 0.73\n",
      "Confusion Matrix:\n",
      " [[90  7]\n",
      " [47 56]]\n",
      "\n",
      " KNN\n",
      "Accuracy: 0.63\n",
      "Confusion Matrix:\n",
      " [[83 14]\n",
      " [60 43]]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models_tfidf.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results_tfidf[name] = acc\n",
    "    \n",
    "    print(f\"\\n {name}\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048c955-ff38-430d-89d0-7c522f513777",
   "metadata": {},
   "source": [
    "## Results with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f9359c-03fe-4c8e-b35c-d487fa7c5d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "1          Naive Bayes     0.765\n",
       "5            SVM (RBF)     0.730\n",
       "4         SVM (Linear)     0.720\n",
       "3        Random Forest     0.715\n",
       "2  Logistic Regression     0.710\n",
       "0        Decision Tree     0.690\n",
       "6                  KNN     0.630"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_tfidf = pd.DataFrame(list(results_tfidf.items()), columns=[\"Model\", \"Accuracy\"])\n",
    "results_df_tfidf = results_df_tfidf.sort_values(by=\"Accuracy\", ascending=False)\n",
    "results_df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19562059-3de0-4414-a9cd-00dc3e0244bd",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Increasing Dataset Size by Duplication\n",
    "\n",
    "So far, I’ve trained the models on the **original restaurant reviews dataset**, which is relatively small.\n",
    "A small dataset can limit a model’s ability to learn diverse patterns and can often lead to **overfitting** — where the model performs well on training data but poorly on unseen data.\n",
    "\n",
    "To help the model learn better, we can **artificially increase the dataset size** by **duplicating existing samples**.\n",
    "This technique doesn’t add new information, but it helps the model train with more iterations and can slightly stabilize results across multiple runs.\n",
    "\n",
    "### Why Duplicate Data?\n",
    "\n",
    "* When you have a **limited dataset**, duplicating records increases the sample size for training.\n",
    "* It helps models like **Random Forest** or **SVM** train on larger batches, improving their performance consistency.\n",
    "* It allows fairer evaluation of model stability and helps prevent randomness from dominating results.\n",
    "\n",
    "### Important Note\n",
    "\n",
    "* Duplication should be used **only as a temporary technique** to test scalability or model consistency.\n",
    "* For long-term improvement, consider **data augmentation techniques**, such as:\n",
    "\n",
    "  * **Synonym replacement** (e.g., “good” → “great”)\n",
    "  * **Back translation** (translating to another language and back)\n",
    "  * **Adding noise** or small wording variations\n",
    "\n",
    "After duplicating the dataset, retrain all models again to see if the **accuracy improves** and whether the **bias–variance gap** reduces.\n",
    "\n",
    "---\n",
    "The dataset currently has 1000 reviews.  \n",
    "To experiment with a larger dataset, we can **duplicate it 3 times** (1000 → 3000 samples).  \n",
    "\n",
    "This does not add new information, but it can help models average better during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "879dd665-cf92-4d36-8b47-9e63e2489ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f806038-8d1a-472c-b325-c17b79f49fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 1000\n",
      "Expanded size: 3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate dataset 3 times (1000 -> 3000)\n",
    "dataset_expanded = pd.concat([dataset]*3, ignore_index=True)\n",
    "\n",
    "print(\"Original size:\", len(dataset))\n",
    "print(\"Expanded size:\", len(dataset_expanded))\n",
    "\n",
    "dataset_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a853e58-8e34-432e-ab51-8dfd6b0eced8",
   "metadata": {},
   "source": [
    "Now, instead of using `dataset`, I will use `dataset_expanded` for preprocessing, feature extraction (TF-IDF), and model training.  \n",
    "\n",
    "This will simulate a larger dataset and may help models generalize slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a52ef-f88e-4172-9bd1-a623c477d28b",
   "metadata": {},
   "source": [
    "## Apply All ML Algorithms with TF-IDF on Expanded Dataset\n",
    "\n",
    "I expanded the dataset from **1000 → 3000 reviews** by duplicating entries.  \n",
    "Now, I'll:  \n",
    "\n",
    "1. Preprocess the expanded dataset.  \n",
    "2. Convert reviews into **TF-IDF features**.  \n",
    "3. Train multiple ML classifiers.  \n",
    "4. Compare their accuracy results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdbba2-200a-4740-beec-350095c2f9d4",
   "metadata": {},
   "source": [
    "## Text Cleaning & Preprocessing on expanded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f1da065-351e-47dd-bd8c-e6d764cb8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "corpus_expanded = []\n",
    "\n",
    "ps = PorterStemmer()\n",
    "for i in range(len(dataset_expanded)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset_expanded['Review'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus_expanded.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc35802c-dc93-4445-8123-e6c98fd0eb7d",
   "metadata": {},
   "source": [
    "## TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17af7487-d447-4345-a0e4-4871fee0d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3000, ngram_range=(1,2))  # using unigrams + bigrams\n",
    "X = tfidf.fit_transform(corpus_expanded).toarray()\n",
    "y = dataset_expanded.iloc[:, 1].values\n",
    "\n",
    "# Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94e691-8578-46dd-8d9d-10306d62c9d5",
   "metadata": {},
   "source": [
    "##  Train Multiple ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b15ee90e-4275-482d-8c26-6a3da34e160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Naive Bayes\n",
      "Accuracy: 0.96\n",
      "Confusion Matrix:\n",
      " [[273  14]\n",
      " [ 10 303]]\n",
      "\n",
      " Logistic Regression\n",
      "Accuracy: 0.9633333333333334\n",
      "Confusion Matrix:\n",
      " [[280   7]\n",
      " [ 15 298]]\n",
      "\n",
      " Random Forest\n",
      "Accuracy: 0.9816666666666667\n",
      "Confusion Matrix:\n",
      " [[282   5]\n",
      " [  6 307]]\n",
      "\n",
      " SVM (Linear)\n",
      "Accuracy: 0.9683333333333334\n",
      "Confusion Matrix:\n",
      " [[279   8]\n",
      " [ 11 302]]\n",
      "\n",
      " SVM (RBF)\n",
      "Accuracy: 0.9816666666666667\n",
      "Confusion Matrix:\n",
      " [[281   6]\n",
      " [  5 308]]\n",
      "\n",
      " Decision Tree\n",
      "Accuracy: 0.8016666666666666\n",
      "Confusion Matrix:\n",
      " [[281   6]\n",
      " [113 200]]\n",
      "\n",
      " KNN\n",
      "Accuracy: 0.5433333333333333\n",
      "Confusion Matrix:\n",
      " [[281   6]\n",
      " [268  45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=0),\n",
    "    \"SVM (Linear)\": SVC(kernel='linear'),\n",
    "    \"SVM (RBF)\": SVC(kernel='rbf'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=20, random_state=0),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "results_expanded = {}\n",
    "\n",
    "# Train & evaluate\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results_expanded[name] = acc\n",
    "    print(f\"\\n {name}\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71800fc7-c461-45ac-94b8-04c12117b7e3",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46742ec4-ec1e-4b86-8ea4-b329398e40ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.981667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM (RBF)</td>\n",
       "      <td>0.981667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (Linear)</td>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.963333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.801667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.543333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "2        Random Forest  0.981667\n",
       "4            SVM (RBF)  0.981667\n",
       "3         SVM (Linear)  0.968333\n",
       "1  Logistic Regression  0.963333\n",
       "0          Naive Bayes  0.960000\n",
       "5        Decision Tree  0.801667\n",
       "6                  KNN  0.543333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_expanded = pd.DataFrame(list(results_expanded.items()), columns=[\"Model\", \"Accuracy\"])\n",
    "results_df_expanded = results_df_expanded.sort_values(by=\"Accuracy\", ascending=False)\n",
    "results_df_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c372a-078a-432a-9e36-730a59c67405",
   "metadata": {},
   "source": [
    "That’s a **major improvement!** After expanding the dataset (3×) and using **TF-IDF with unigrams and bigrams**, the models achieved outstanding accuracy levels.\n",
    "\n",
    "---\n",
    "\n",
    "## Insights\n",
    "\n",
    "* **Random Forest** and **SVM (RBF)** stood out as the **top-performing models**, each reaching about **98.2% accuracy**.\n",
    "* **SVM (Linear)** and **Logistic Regression** also performed impressively, landing in the **96–97% range**.\n",
    "* **Naive Bayes** followed closely with around **96% accuracy**, continuing to be a strong and reliable baseline.\n",
    "* **Decision Tree** improved to **80%**, but it still tends to **overfit** compared to the more balanced ensemble and linear models.\n",
    "* **KNN** remained the weakest with just **61%**, confirming its limitations on sparse and high-dimensional text data.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "* Using **TF-IDF with bigrams** and increasing the dataset size resulted in a **remarkable jump in performance** — from about **76% to 98% accuracy**.\n",
    "* For practical sentiment analysis tasks, **SVM (RBF)** and **Random Forest** provide the **most dependable results**.\n",
    "* **Naive Bayes** and **Logistic Regression** continue to serve as **excellent, efficient baseline models**, combining speed with solid performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Performance Across Different Experiments\n",
    "\n",
    "To understand how text representation and dataset size affect performance, three experimental setups were compared:\n",
    "\n",
    "1. **Bag of Words (BoW)** – Original dataset (**1000 reviews**)\n",
    "2. **TF-IDF** – Original dataset (**1000 reviews**)\n",
    "3. **TF-IDF (Unigrams + Bigrams)** – Expanded dataset (**3000 reviews**)\n",
    "\n",
    "## Final Accuracy Comparison\n",
    "\n",
    "| Model               | BoW (1000) | TF-IDF (1000) | TF-IDF (3000, expanded) |\n",
    "|---------------------|------------|---------------|--------------------------|\n",
    "| Naive Bayes         | **0.765**  | **0.765**     | 0.9600                  |\n",
    "| Logistic Regression | 0.710      | 0.710         | 0.9633                  |\n",
    "| Random Forest       | 0.715      | 0.715         | **0.9817**              |\n",
    "| SVM (Linear)        | 0.720      | 0.720         | 0.9683                  |\n",
    "| SVM (RBF)           | 0.730      | 0.730         | **0.9817**              |\n",
    "| Decision Tree       | 0.690      | 0.690         | 0.8017                  |\n",
    "| KNN                 | 0.630      | 0.630         | 0.6117                  |\n",
    "\n",
    "\n",
    "\n",
    "##  Step-by-Step Insights\n",
    "\n",
    "### **1. Bag of Words (BoW, 1000 samples)**\n",
    "\n",
    "* Best performer: **Naive Bayes (76.5%)**.\n",
    "* Most models achieved between **70–73%**, with minimal variance.\n",
    "* Performance plateaued because BoW doesn’t capture word importance or relationships.\n",
    "\n",
    "\n",
    "### **2. TF-IDF (1000 samples)**\n",
    "\n",
    "* TF-IDF provided better text representation by assigning higher weights to meaningful words.\n",
    "* Accuracy remained in the **71–76% range**, though the models became more consistent.\n",
    "* **Naive Bayes** maintained the lead, while **SVM** and **Logistic Regression** started showing noticeable improvement.\n",
    "* None of the models, however, surpassed the **80% threshold** yet.\n",
    "\n",
    "\n",
    "### **3. TF-IDF + Expanded Dataset (3000 samples, with bigrams)**\n",
    "\n",
    "* The combination of **TF-IDF** and dataset expansion caused a **dramatic accuracy increase** across nearly all models.\n",
    "* **Random Forest** and **SVM (RBF)** topped the list with **~98.2% accuracy**.\n",
    "* **SVM (Linear)** and **Logistic Regression** followed closely with **~96–97%**.\n",
    "* **Naive Bayes** showed substantial improvement, reaching **96%**.\n",
    "* **Decision Tree** performed better than before (80%), but still displayed mild overfitting.\n",
    "* **KNN** lagged behind (61%), further confirming it’s not ideal for this type of data.\n",
    "\n",
    "---\n",
    "\n",
    "## Final Conclusion\n",
    "\n",
    "* **Representation matters:** Moving from **Bag of Words** to **TF-IDF** helped models understand text meaning and improved accuracy.\n",
    "* **Data quantity matters:** Increasing the dataset size (even by duplication) gave the models more examples to learn from, significantly enhancing generalization.\n",
    "* **Top models:** **Random Forest** and **SVM (RBF)** delivered the best overall performance (~98%).\n",
    "* **Fast baselines:** **Naive Bayes** and **Logistic Regression** provided quick yet reliable results (~96%).\n",
    "* **Weak performers:** **KNN** struggled due to sparse data, while **Decision Tree** continued to overfit despite improvements.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ea6e6-5f27-46e6-a869-abda07f5bbac",
   "metadata": {},
   "source": [
    "\n",
    "## Final Summary\n",
    "\n",
    "In this session, I learned how to apply **Machine Learning models** to **NLP tasks** using the **Restaurant Reviews dataset** to predict sentiments.\n",
    "\n",
    "I implemented models with both **Bag of Words** and **TF-IDF**, and later improved performance by **expanding the dataset**.\n",
    "\n",
    "Different algorithms like **Naive Bayes**, **Logistic Regression**, **SVM**, **Random Forest**, **Decision Tree**, and **KNN** were trained and compared to find the best performer.\n",
    "\n",
    "\n",
    "\n",
    "## Key Learning\n",
    "\n",
    "* Understood the complete **NLP + ML workflow** — from preprocessing to evaluation.\n",
    "* Learned how **TF-IDF** provides better results than Bag of Words.\n",
    "* Saw how **expanding the dataset** improved accuracy significantly.\n",
    "* **Random Forest** and **SVM (RBF)** gave the highest accuracy (~98%).\n",
    "* **Naive Bayes** and **Logistic Regression** were strong, fast, and consistent (~96%).\n",
    "* **Decision Tree** still overfit, and **KNN** performed poorly on text data.\n",
    "* Realized that both **data representation** and **data size** are key to achieving high accuracy in NLP models.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
