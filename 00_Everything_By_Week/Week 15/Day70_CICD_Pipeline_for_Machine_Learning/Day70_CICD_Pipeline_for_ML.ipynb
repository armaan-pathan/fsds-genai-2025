{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d1a1b8-c542-401b-950d-8ae8564ec86e",
   "metadata": {},
   "source": [
    "# Day 70 - CI/CD Pipeline for Machine Learning\n",
    "\n",
    "In this notebook, I learned how to automate the **training and testing of machine learning models** using a **Continuous Integration and Continuous Deployment (CI/CD)** pipeline.\n",
    "\n",
    "The goal was to:\n",
    "- Understand how CI/CD fits into the **MLOps lifecycle**\n",
    "- Create a simple ML project structure compatible with CI/CD\n",
    "- Automate testing and model training using **GitHub Actions**\n",
    "- Learn how workflows can be triggered automatically on push or pull requests\n",
    "\n",
    "This setup helps ensure that every change in the codebase is **automatically tested, trained, and validated**, making the ML workflow more robust and production-ready.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Introduction**\n",
    "\n",
    "**CI/CD** stands for **Continuous Integration** and **Continuous Deployment (or Delivery)**.\n",
    "\n",
    "In traditional software engineering, CI/CD automates the process of integrating new code, testing it, and deploying it into production.\n",
    "\n",
    "For **Machine Learning (ML)** projects, CI/CD ensures that every time new data or code changes are made, the ML pipeline — including **data processing, model training, evaluation, and deployment** — runs automatically, ensuring consistent, reliable, and reproducible results.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Why CI/CD is Used in Machine Learning**\n",
    "\n",
    "ML projects differ from traditional software projects because they include:\n",
    "\n",
    "* **Data dependency** — Models rely heavily on the quality and version of data.\n",
    "* **Model retraining** — Models need regular retraining when new data arrives.\n",
    "* **Experiment tracking** — Different hyperparameters, algorithms, and metrics must be recorded.\n",
    "* **Automation** — Manual training and evaluation take time; automation ensures faster delivery and fewer human errors.\n",
    "\n",
    "Hence, CI/CD in ML automates:\n",
    "\n",
    "* The **training and evaluation** process whenever code or data changes.\n",
    "* The **testing of code** (e.g., data validation, model accuracy thresholds).\n",
    "* The **deployment** of updated models into production environments automatically.\n",
    "\n",
    "**Benefits:**\n",
    "\n",
    "* Ensures **consistency** across environments.\n",
    "* Reduces **manual intervention** and **errors**.\n",
    "* Enables **faster iteration** and **reproducibility**.\n",
    "* Simplifies **collaboration** through version control and automation.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Tools Commonly Used in CI/CD for ML**\n",
    "\n",
    "| **Stage**                  | **Tools Used**                                  |\n",
    "| -------------------------- | ----------------------------------------------- |\n",
    "| **Version Control**        | Git, GitHub, GitLab                             |\n",
    "| **CI/CD Automation**       | GitHub Actions, Jenkins, GitLab CI/CD, CircleCI |\n",
    "| **Experiment Tracking**    | MLflow, DVC, Weights & Biases                   |\n",
    "| **Containerization**       | Docker                                          |\n",
    "| **Cloud/Deployment**       | AWS, GCP, Azure, Streamlit, Flask               |\n",
    "| **Testing**                | Pytest, Unittest                                |\n",
    "| **Environment Management** | Conda, pip, requirements.txt                    |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Typical CI/CD Workflow for ML Pipeline**\n",
    "\n",
    "Here’s how a **typical CI/CD ML pipeline** is structured —\n",
    "\n",
    "- **Step 1: Data Extraction and Cleaning**\n",
    "- **Step 2: Train/Test Split**\n",
    "- **Step 3: Model Building**\n",
    "- **Step 4: Model Evaluation**\n",
    "- **Step 5: Save Outputs**\n",
    "- **Step 6: Push Code and Files to GitHub**\n",
    "- **Step 7: Create a GitHub Actions Workflow**\n",
    "- **Step 8: CI/CD Auto-Runs Pipeline**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e26f0d-c977-41bb-82b2-a273015133be",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af2205a-9a4e-4f85-8978-1bf4f19ca708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score, recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc60e93b-89c0-4246-9ee3-3c5e191b2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataset = pd.read_csv(r'C:\\Arman\\FSDS GenAI 2025\\Practice\\CICD Pipeline\\iris.csv')\n",
    "\n",
    "# Feature names (Ensure no extra spaces or parentheses)\n",
    "dataset.columns = [colname.strip(' (cm)').replace(\" \", \"_\") for colname in dataset.columns.tolist()]\n",
    "features_names = dataset.columns.tolist()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "988ee0bd-38d3-42ed-bb3b-7f988d77a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "dataset['sepal_length_width_ratio'] = dataset['sepal_length'] / dataset['sepal_width']\n",
    "dataset['petal_length_width_ratio'] = dataset['petal_length'] / dataset['petal_width']\n",
    "\n",
    "# Select Features (Correct the duplicate column issue)\n",
    "dataset = dataset[['sepal_length', 'sepal_width', 'petal_length', 'petal_width', \n",
    "                   'sepal_length_width_ratio', 'petal_length_width_ratio', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ff3166-8638-4a5d-8bc7-8c597cde531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=44)\n",
    "\n",
    "# X_train, y_train, X_test, y_test\n",
    "X_train = train_data.drop('target', axis=1).values.astype('float32')\n",
    "y_train = train_data.loc[:, 'target'].values.astype('int32')\n",
    "X_test = test_data.drop('target', axis=1).values.astype('float32')\n",
    "y_test = test_data.loc[:, 'target'].values.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9056232c-5fd3-4e78-8d64-548b37b59d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression(C=0.0001, solver='lbfgs', max_iter=100, multi_class='multinomial')\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions_lr = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e52219a-0215-485a-a401-0b94355f888b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lr = confusion_matrix(y_test, predictions_lr)\n",
    "f1_lr = f1_score(y_test, predictions_lr, average='micro')\n",
    "prec_lr = precision_score(y_test, predictions_lr, average='micro')\n",
    "recall_lr = recall_score(y_test, predictions_lr, average='micro')\n",
    "# Accuracy\n",
    "train_acc_lr = logreg.score(X_train, y_train) * 100\n",
    "test_acc_lr = logreg.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06daffcc-ad3e-4a79-a82c-c2371cf1daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train, y_train)\n",
    "predictions_rf = rf_reg.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predictions_rf_class = np.round(predictions_rf).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13a964c-bcb0-4a1f-a974-2f6abec6510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_rf = f1_score(y_test, predictions_rf_class, average='micro')\n",
    "prec_rf = precision_score(y_test, predictions_rf_class, average='micro')\n",
    "recall_rf = recall_score(y_test, predictions_rf_class, average='micro')\n",
    "\n",
    "# Accuracy\n",
    "train_acc_rf = rf_reg.score(X_train, y_train) * 100\n",
    "test_acc_rf = rf_reg.score(X_test, y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd401db-9efe-4485-9963-33759b50f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Scores to a File\n",
    "with open('scores.txt', \"w\") as score:\n",
    "    score.write(\"Random Forest Train Var: %2.1f%%\\n\" % train_acc_rf)\n",
    "    score.write(\"Random Forest Test Var: %2.1f%%\\n\" % test_acc_rf)\n",
    "    score.write(\"F1 Score: %2.1f%%\\n\" % f1_rf)\n",
    "    score.write(\"Recall Score: %2.1f%%\\n\" % recall_rf)\n",
    "    score.write(\"Precision Score: %2.1f%%\\n\" % prec_rf)\n",
    "\n",
    "    score.write(\"\\n\\n\")\n",
    "\n",
    "    score.write(\"Logistic Regression Train Var: %2.1f%%\\n\" % train_acc_lr)\n",
    "    score.write(\"Logistic Regression Test Var: %2.1f%%\\n\" % test_acc_lr)\n",
    "    score.write(\"F1 Score: %2.1f%%\\n\" % f1_lr)\n",
    "    score.write(\"Recall Score: %2.1f%%\\n\" % recall_lr)\n",
    "    score.write(\"Precision Score: %2.1f%%\\n\" % prec_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34662eb-e1a3-4fd7-93f7-b9a3eab141a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **GitHub Setup for CI/CD Pipeline**\n",
    "\n",
    "Once the local machine learning pipeline is complete, the next step is to automate it using **GitHub Actions**.\n",
    "\n",
    "Follow these steps to set up the CI/CD pipeline for your ML project:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Create a New GitHub Repository**\n",
    "\n",
    "1. Go to [https://github.com/new](https://github.com/new).\n",
    "2. Create a new repository named **`cicd_pipeline`** (you can choose it as public or private).\n",
    "\n",
    "\n",
    "### **Step 2: Upload Project Files**\n",
    "\n",
    "After creating the repository, upload all the necessary files for the pipeline:\n",
    "\n",
    "**Files to upload:**\n",
    "\n",
    "* `iris.csv` → Dataset file\n",
    "* `train_model.py` → Python script that trains and evaluates the model\n",
    "* `requirements.txt` → List of dependencies required for the pipeline\n",
    "\n",
    "\n",
    "### **Step 3: Create GitHub Actions Workflow Folder**\n",
    "\n",
    "Inside the repository, create a hidden folder named **`.github/workflows/`**.\n",
    "\n",
    "This folder will contain your CI/CD workflow configuration file.\n",
    "\n",
    "\n",
    "### **Step 4: Add the Workflow File (`run.yml`)**\n",
    "\n",
    "Create a new file named **`run.yml`** inside the `.github/workflows/` folder.\n",
    "\n",
    "This file defines the CI/CD pipeline steps that GitHub Actions will execute every time you push or commit changes.\n",
    "\n",
    "\n",
    "### **Step 5: Commit and Push Changes**\n",
    "\n",
    "After adding the workflow file, commit and push all files to GitHub:\n",
    "\n",
    "\n",
    "### **Step 6: View CI/CD Pipeline in GitHub Actions Tab**\n",
    "\n",
    "1. Go to your repository on GitHub.\n",
    "2. Click on the **“Actions”** tab (next to Code, Issues, Pull Requests).\n",
    "3. You’ll see a workflow named **“CI-CD Pipeline”** running automatically.\n",
    "4. The pipeline performs the following:\n",
    "\n",
    "   * Installs dependencies.\n",
    "   * Executes your training script (`train_model.py`).\n",
    "   * Validates successful model training.\n",
    "\n",
    "If everything is correctly configured, you’ll see a green **“Workflow run completed successfully”** message.\n",
    "\n",
    "\n",
    "### **Final Outcome**\n",
    "\n",
    "After completing all steps:\n",
    "\n",
    "* Your ML pipeline is **automated**.\n",
    "* Every push or pull request to the repository triggers the **training workflow**.\n",
    "* The workflow ensures that:\n",
    "\n",
    "  * All dependencies are installed,\n",
    "  * The ML model is trained and evaluated,\n",
    "  * Errors are caught early before deployment.\n",
    "\n",
    "---\n",
    "\n",
    "## **GitHub Setup and Execution Screenshots**\n",
    "\n",
    "Below are the step-by-step visuals showing how the CI/CD pipeline was created and executed using **GitHub Actions**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Creating the Repository and Uploading Files**\n",
    "\n",
    "You can see the newly created repository named **`cicd_pipeline`**.\n",
    "\n",
    "The essential files — `iris.csv`, `train_model.py`, and `requirements.txt` — have been uploaded successfully.\n",
    "\n",
    "*Repository structure after uploading files*\n",
    "\n",
    "![Repository structure](screenshots\\screenshot1.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Creating the Workflow Folder and File**\n",
    "\n",
    "Inside the repository, a new folder `.github/workflows/` is created, and within it, a file named **`run.yml`** is added.\n",
    "\n",
    "This file defines the CI/CD workflow that will automatically execute the ML pipeline.\n",
    "\n",
    "*Creating `.github/workflows/run.yml` file in GitHub*\n",
    "![Creating run.yml file](screenshots\\screenshot2.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Adding the Workflow File (run.yml)**\n",
    "\n",
    "The workflow file named `run.yml` was added inside `.github/workflows/`.\n",
    "\n",
    "This file defines the steps that GitHub Actions will perform automatically whenever new code is pushed to the repository.\n",
    "\n",
    "\n",
    "*Repository showing `.github/workflows/run.yml` file created*\n",
    "![Workflow file added](screenshots\\screenshot3.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Initial Commit and Pipeline Trigger**\n",
    "\n",
    "\n",
    "After committing and pushing the workflow file, the pipeline automatically starts running.\n",
    "\n",
    "You can see the **“Model Training CICD”** workflow triggered under the **Actions** tab.\n",
    "\n",
    "*Workflow run started in GitHub Actions*\n",
    "![Pipeline triggered](screenshots\\screenshot4.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Debugging the First Pipeline Failure**\n",
    "\n",
    "The initial workflow run failed because the dataset path used was an absolute local path.\n",
    "\n",
    "This was fixed by updating the path in `train_model.py` to a relative one (`iris.csv`).\n",
    "\n",
    "*Initial failed pipeline run showing the error in Actions tab*\n",
    "![Failed pipeline](screenshots\\screenshot5.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 6: Successful Pipeline Execution**\n",
    "\n",
    "After correcting the path, a new commit triggered the workflow again — this time it executed successfully.\n",
    "\n",
    "All steps (setup, checkout, train model) completed without errors, indicated by the green check mark ✅.\n",
    "\n",
    "*Successful CI/CD pipeline run in GitHub Actions*\n",
    "![Successful run](screenshots\\screenshot6.png)\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Outcome**\n",
    "\n",
    "* The CI/CD pipeline automatically trains and evaluates the ML model on every push.\n",
    "* Any future code or data updates will trigger the same automated workflow.\n",
    "* This ensures consistent, reproducible, and testable ML model training.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e42513",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated how to integrate **CI/CD principles** into a machine learning workflow using **GitHub Actions**.  \n",
    "The pipeline automatically:\n",
    "- Triggers when new code is pushed to the repository  \n",
    "- Executes training and evaluation scripts  \n",
    "- Validates model performance  \n",
    "- Ensures the workflow remains stable and reproducible  \n",
    "\n",
    "This setup helps bridge the gap between **machine learning development and deployment**, creating a reliable automation process for model updates.\n",
    "\n",
    "\n",
    "## Key Learnings\n",
    "\n",
    "- Understood how CI/CD connects to the **MLOps lifecycle**\n",
    "- Learned how to define a **GitHub Actions workflow** for ML automation\n",
    "- Implemented **automated training and evaluation** through pipeline jobs\n",
    "- Experienced how pipelines ensure **consistency and reproducibility** in ML models\n",
    "- Observed how automation can catch issues early before production deployment\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
